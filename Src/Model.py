# -*- coding: utf-8 -*-
"""pro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FWOTlwgdh1F-oEOk_z9FQ7GBo0IWfvN3
"""

# Enabling Tpu Version

import tensorflow as tf
print("Tensorflow version " + tf.__version__)

try:
  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection
  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])
except ValueError:
  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')

tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)

# Mounting my google drive

from google.colab import drive
drive.mount('/content/drive')

# installing trimesh library that is used for loading of 3d images

!pip install trimesh

# importing necessary packages
import os
import trimesh
import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization
from sklearn.metrics import mean_absolute_error

"""# Data Creation"""

# Female Data

# Reading Female(.obj) data and converting every image into Numerical Data and Storing them in list called array
a =[]
for image in os.listdir('/content/drive/MyDrive/Nomo/female_obj'):
   if image.endswith('.obj'):
      image_path = f"/content/drive/MyDrive/Nomo/female_obj/{image}"
      a.append(image_path)

# i wnat to remive these duplicate files
 duplicate = ['/content/drive/MyDrive/Nomo/female_obj/female_0061_promt.obj', '/content/drive/MyDrive/Nomo/female_obj/female_0089_promt.obj',

 '/content/drive/MyDrive/Nomo/female_obj/female_0092_promt.obj', '/content/drive/MyDrive/Nomo/female_obj/female_0137_promt.obj', '/content/drive/MyDrive/Nomo/female_obj/female_0164_promt.obj']

a = [b for b in a if b not in duplicate]

files = []
# iterate through all file
for file in os.listdir('/content/drive/MyDrive/Nomo/female_TC2Meas_txt/female_TC2Meas_txt'):
	# Check whether file is in text format or not
		file_path = f"C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/{file}"
		files.append(file_path)

# sorting the images

files.sort()

# Extracting Vertices from the female images

a

ve=[]
for i in range(154):
  mesh = trimesh.load(a[i])
  vertices = np.array(mesh.vertices)
  rem_vertices = 62244-vertices.shape[0]
  if rem_vertices>0:
    for v in range(rem_vertices):
      vertices = np.append(vertices,np.array([[0,0,0]]),axis=0)
  ve.append(vertices)

df = pd.read_csv('/content/drive/MyDrive/Nomo/dataset.csv')

dupl = ['C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/.ipynb_checkpoints','C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0062_promt.txt','C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0077_promt.txt', 'C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0087_copy.txt''C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0161_promt.txt','C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0174_promt.txt','C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0161_promt.txt', 'C:/Users/SAI/Downloads/NOMO-3d-400-scans_and_tc2_measurements/NOMO-3d-400-scans_and_tc2_measurements/nomo-scans/female_TC2Meas_txt/female_TC2Meas_txt/female_0087_copy.txt'
]

# removing dupl rows from the dataframe

df = df[~df['filename'].str.contains('|'.join(dupl))]

female_data = {'MEASURE Seat_Back_Angle':df['MEASURE Seat_Back_Angle'], 'MEASURE CrotchLength_Front':df[ 'MEASURE CrotchLength_Front'], 'MEASURE CrotchLength_Back':df['MEASURE CrotchLength_Back'], 'MEASURE Knee_Circ':df['MEASURE Knee_Circ'], 'MEASURE Calf_Circ':df[ 'MEASURE Calf_Circ'], 'MEASURE Outseam':df['MEASURE Outseam'], 'MEASURE Inseam':df['MEASURE Inseam'], 'MEASURE Shoulder_to_Wrist':df['MEASURE Shoulder_to_Wrist'], 'MEASURE Bicep_Circ':df['MEASURE Bicep_Circ'], 'MEASURE Elbow_Circ':df['MEASURE Elbow_Circ'], 'MEASURE Wrist_Circ':df['MEASURE Wrist_Circ'], 'MEASURE Shoulder_to_Shoulder':df['MEASURE Shoulder_to_Shoulder'], 'MEASURE Across_Front':df['MEASURE Across_Front'], 'MEASURE Neck_Circ':df['MEASURE Neck_Circ']}

y1 = pd.DataFrame(female_data)

y11 = y1.head(154)

y1.shape

y1.shape

"""Male Data"""

# Reading Female(.obj) data and converting every image into Numerical Data and Storing them in list called array
b =[]
for image in os.listdir('/content/drive/MyDrive/Nomo/male_obj/male_obj'):
  if image.endswith('.obj'):
    image_path = f"/content/drive/MyDrive/Nomo/male_obj/male_obj/{image}"
    b.append(image_path)

# Extracting vertices from male data

b

# sorting the images

b.sort()

#duplicated images

n = [ '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0147_promt.obj', '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0102_promt.obj', '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0100_promt.obj',
 '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0104_promt.obj',

 '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0111_promt.obj', '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0169_promt.obj', '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0122_promt.obj',

 '/content/drive/MyDrive/Nomo/male_obj/male_obj/male_0123_promt.obj',

]

imgs = [img for img in b if img not in n]

imgs.sort()

imgs[159]

# Extracting the vertices from the female images

arre = []
for i in range(159):
  mesh = trimesh.load(imgs[i])
  vertices = np.array(mesh.vertices)
  remaining_rows=62244-vertices.shape[0]
  for j in range(remaining_rows):
    vertices = np.append(vertices,np.array([[0,0,0]]),axis=0)
  arre.append(vertices)

arre = np.array(arre)
ve = np.array(ve)

# creating an array by concatenating two arrays one is male data and other one is female data

array = np.concatenate((arre,ve),axis=0)

arre.shape

y1.shape

len(ve)

ve.shape

x = array

# reading male data from my drive

male = pd.read_csv('/content/drive/MyDrive/Nomo/file.csv')

male_data = {'MEASURE Seat_Back_Angle':male['MEASURE Seat_Back_Angle'], 'MEASURE CrotchLength_Front':male[ 'MEASURE CrotchLength_Front'], 'MEASURE CrotchLength_Back':male['MEASURE CrotchLength_Back'], 'MEASURE Knee_Circ':male['MEASURE Knee_Circ'], 'MEASURE Calf_Circ':male[ 'MEASURE Calf_Circ'], 'MEASURE Outseam':male['MEASURE Outseam'], 'MEASURE Inseam':male['MEASURE Inseam'], 'MEASURE Shoulder_to_Wrist':male['MEASURE Shoulder_to_Wrist'], 'MEASURE Bicep_Circ':male['MEASURE Bicep_Circ'], 'MEASURE Elbow_Circ':male['MEASURE Elbow_Circ'], 'MEASURE Wrist_Circ':male['MEASURE Wrist_Circ'], 'MEASURE Shoulder_to_Shoulder':male['MEASURE Shoulder_to_Shoulder'], 'MEASURE Across_Front':male['MEASURE Across_Front'], 'MEASURE Neck_Circ':male['MEASURE Neck_Circ']}

y2 = pd.DataFrame(male_data)

y22 = y2.head(159)

y = pd.concat([y11,y22],axis=0)

"""# Data Normalization"""

# Normalizing the array values

x = x/x.max()

x

"""Creating a Convolutional Architecture"""

model = Sequential()
model.add(Conv2D(32, (3, 3),padding='same',activation='relu', input_shape=(62244,3,1)))
model.add(MaxPool2D(pool_size=(2, 2),padding='same'))
model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))
model.add(Conv2D(128, (3, 3),padding='same',activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2),padding='same'))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(14, activation='linear'))
# Compile the model
model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mean_absolute_error'])

# model fitting

model.fit(x,y,epochs=15,batch_size=120)

""" # Creating Validation data to validate model"""

# Validating the model with untrained images of female and male

a.sort()

# traversing through untrained female

val_ver=[]
for i in range(154,176):
  mesh = trimesh.load(a[i])
  val_vertices = np.array(mesh.vertices)
  remaining_rows=62244-val_vertices.shape[0]
  for j in range(remaining_rows):
    val_vertices = np.append(val_vertices,np.array([[0,0,0]]),axis=0)
  val_ver.append(val_vertices)

imgs[160]

# traversing through untrained male

val_vert=[]
for i in range(160,179):
  mesh = trimesh.load(imgs[i])
  Val_vertices = np.array(mesh.vertices)
  remaining_rows=62244-Val_vertices.shape[0]
  for j in range(remaining_rows):
    Val_vertices = np.append(Val_vertices,np.array([[0,0,0]]),axis=0)
  val_vert.append(Val_vertices)

y111 = y1.tail(22)

y222 = y2.tail(19)

val_x = np.concatenate((val_ver,val_vert),axis=0)

val_x = val_x/val_x.max()

val_y = pd.concat((y111,y222),axis=0)

pred_y = model.predict(val_x)

val_x.shape

val_y.shape

"""# Evaluating the model performance"""

from sklearn.metrics import mean_absolute_error

mean_absolute_error(pred_y,val_y)

# now the mean_absolute_error of the model is 4.026460503036552 which is a god sign that model is performing very well